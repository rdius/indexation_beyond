{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_jsonl(mtd, outfilename):\n",
    "    with open(outfilename, 'a+', encoding='utf8') as outfile:\n",
    "        #for entry in JSON_file:\n",
    "        json.dump(mtd, outfile, ensure_ascii=False)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# Use this fnx to get all habitats for a given micro-organism\n",
    "# Input : data -> relations.full pandas Dataframe\n",
    "# Output : Jsonl file from save_to_jsonl() fnx, to be indexed in ES (logstash input)\n",
    "#############\n",
    "def process_beyond_db(data):\n",
    "    longList = []\n",
    "    data['orgdict']=data[['form_microorganism','taxid','pmid','paths_microorganism', 'offset_microorganism', 'form_habitat']].to_dict(\"records\")\n",
    "    data['microorganism'] = 'microorganism'\n",
    "    df = data[['microorganism','orgdict']]\n",
    "    df['microorganism'] = df['microorganism'].apply(str) #Converting integer column 'label' to string\n",
    "    df = df.groupby('microorganism')['orgdict'].apply(list) \n",
    "    desired_dict = df.to_dict()\n",
    "    \n",
    "    data['habtdict']=data[['form_habitat','obtid','pmid','paths_habitat', 'offset_habitat']].to_dict(\"records\")\n",
    "    data['habitat'] = 'habitat'\n",
    "    df = data[['habitat','habtdict']]\n",
    "    df['habitat'] = df['habitat'].apply(str) #Converting integer column 'label' to string\n",
    "    df = df.groupby('habitat')['habtdict'].apply(list) \n",
    "    desired_dict_hab = df.to_dict()\n",
    "    \n",
    "    d = (pd.DataFrame(desired_dict['microorganism'])\n",
    "       .groupby(['form_microorganism'])\n",
    "       .agg(set)\n",
    "       .reset_index()\n",
    "       .to_dict('r'))\n",
    "    \n",
    "    dhb = (pd.DataFrame(desired_dict_hab['habitat'])\n",
    "       .groupby(['form_habitat'])\n",
    "       .agg(set)\n",
    "       .reset_index()\n",
    "       .to_dict('r'))\n",
    "    \n",
    "    for v in d:\n",
    "        v['habitats'] = []\n",
    "        v['taxid'] = list(v['taxid'])[0]\n",
    "    #     v['pmid'] = list(v['pmid'])\n",
    "        v['pmid'] = [str(val) for val in list(v['pmid'])]\n",
    "        v['paths_microorganism'] = list(v['paths_microorganism'])[0]\n",
    "        v['offset_microorganism'] = list(v['offset_microorganism'])\n",
    "        v['form_habitat'] = list(v['form_habitat'])\n",
    "        \n",
    "    for v in dhb:\n",
    "    #     v['habitats'] = []\n",
    "        v['obtid'] = list(v['obtid'])[0]\n",
    "#         v['pmid'] = list(v['pmid'])\n",
    "        v['pmid'] = [str(val) for val in list(v['pmid'])]\n",
    "        v['paths_habitat'] = list(v['paths_habitat'])[0]\n",
    "        v['offset_habitat'] = list(v['offset_habitat'])[0]\n",
    "        \n",
    "    for i in range(len(d)):\n",
    "        for j in range(len(dhb)):\n",
    "            if dhb[j]['form_habitat'] in d[i]['form_habitat']:\n",
    "                d[i]['habitats'].append(dhb[j]) \n",
    "            #     print(dhb[0]['form_habitat'])\n",
    "    \n",
    "    # D['Microorganism'].append(d[0])\n",
    "    for mi in d:\n",
    "        D = {}\n",
    "        D['Microorganism'] = []\n",
    "        D['Microorganism'].append(mi)\n",
    "        save_to_jsonl(D, 'beyond_db.jsonl')\n",
    "#         longList.append(D)\n",
    "#     return longList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### \n",
    "#  Use this fnx to get each relation (miroorganism <-> habitats) with translated paths\n",
    "# Build Losgstash input data for ES from these input data :\n",
    "# 1 - relations file\n",
    "# 2 - BioNLP_onto,\n",
    "# 3 - taxid_microorganisms\n",
    "#####\n",
    "def beyond_db_preprocess(relations,BioNLP_onto,taxid_microorganisms):\n",
    "#     relations = \"/home/rodrique/Bureau/Jupyter-notebook/Beyond/data-examples/relations.full.tsv/relations_min.tsv\"\n",
    "    data = pd.read_csv(relations, delimiter='\\t')\n",
    "    df = data[['form_microorganism', 'lemma_microorganism', 'paths_microorganism','pmid', 'section', 'taxid',\n",
    "        'canonical_microorganism', \n",
    "       'obtid', 'form_habitat', 'lemma_habitat', 'canonical_habitat',\n",
    "       'paths_habitat', 'offset_microorganism', 'offset_habitat']]\n",
    "    filtered_df = df[df['form_microorganism'].notnull()]\n",
    "    \n",
    "    filtered_df_dic = filtered_df.to_dict('records')\n",
    "    val = list(map(dict, set(tuple(sorted(d.items())) for d in filtered_df_dic)))\n",
    "    print(len(val))\n",
    "    \n",
    "    test = filtered_df[:5] # consider subset for test\n",
    "    \n",
    "    # define translated path --> ordered list of habitats\n",
    "    test['translated_path_habitat'] = test['paths_habitat'].str.split(\"/\")\n",
    "        \n",
    "    dc = {}\n",
    "    synod = {}\n",
    "    with open (BioNLP_onto, \"r\") as hfile:\n",
    "        sp = hfile.read()\n",
    "        lines = sp.split(\"\\n\\n\")\n",
    "        for line in lines:\n",
    "            item = line.split('\\n\\n\\n')\n",
    "            items = [i.split('\\n') for i in item]\n",
    "            items = [x.split(': ') for x in items[0]]\n",
    "            id_name = [l for l in items if l[0]=='id' or l[0]=='name']\n",
    "            syno =  [l for l in items if l[0]=='id' or l[0]=='synonym']\n",
    "\n",
    "            if len(id_name)>0:\n",
    "                dc[id_name[0][1]] = id_name[1][1]\n",
    "            #   print(syno)\n",
    "            ########## We can add synonyms if needed\n",
    "            if len(syno)>1:\n",
    "                synod[syno[0][1]] = [ i[1] for i in syno[1:]]\n",
    "            ############\n",
    "\n",
    "    for k,v in dc.items():\n",
    "        test['translated_path_habitat'] = test.apply(lambda x:[i.replace(k,v) for i in x['translated_path_habitat'] if i], axis=1)\n",
    "        \n",
    "    # pop current habitat from the path\n",
    "    test['translated_path_habitat'] = test['translated_path_habitat'].apply(lambda x:x[:-1])\n",
    "    \n",
    "    \n",
    "    ############Build translated path for each micro-organism\n",
    "#     taxid_microorganisms = '/home/rodrique/Bureau/Jupyter-notebook/Beyond/data-examples/taxid_microorganisms.tsv/taxid_microorganisms.tsv'\n",
    "    taxid_data = pd.read_csv(taxid_microorganisms, delimiter='\\t')\n",
    "    \n",
    "    taxid_data = taxid_data[ ['taxid', 'taxon']]\n",
    "    \n",
    "    taxid_data_dic = taxid_data.set_index('taxid').T.to_dict('r')\n",
    "    \n",
    "    test['translated_paths_microorganism'] = test['paths_microorganism'].str.split(\"/\")\n",
    "    \n",
    "    for k,v in taxid_data_dic[0].items():\n",
    "        test['translated_paths_microorganism'] = test.apply(lambda x:[i.replace(k,v) for i in x['translated_paths_microorganism'] if i], axis=1)\n",
    "    \n",
    "    # pop current habitat from the path\n",
    "    test['translated_paths_microorganism'] = test['translated_paths_microorganism'].apply(lambda x:x[:-1])\n",
    "\n",
    "    test_dic = test.to_dict('records')    \n",
    "    for d in test_dic:\n",
    "        d['pmid'] = str(d['pmid'])\n",
    "        \n",
    "    ################### Save record!\n",
    "    for mtd in test_dic:\n",
    "        save_to_jsonl(mtd, 'beyond_db_uniq5.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = \"./data-examples/relations.full.tsv/relations_min.tsv\"\n",
    "BioNLP_onto = './data-examples/BioNLP-OST+EnovFood.txt'\n",
    "taxid_microorganisms = './data-examples/taxid_microorganisms.tsv/taxid_microorganisms.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrique/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,12,13,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrique/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/rodrique/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/rodrique/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/rodrique/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:59: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "/home/rodrique/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/rodrique/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "beyond_db_preprocess(relations,BioNLP_onto,taxid_microorganisms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
